{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Info:\n",
      "Shape: (1000, 21)\n",
      "Column names: ['checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings_status', 'employment', 'installment_commitment', 'personal_status', 'other_parties', 'residence_since', 'property_magnitude', 'age', 'other_payment_plans', 'housing', 'existing_credits', 'job', 'num_dependents', 'own_telephone', 'foreign_worker', 'class']\n",
      "\n",
      "Sample data:\n",
      "  checking_status  duration                    credit_history  \\\n",
      "0            '<0'         6  'critical/other existing credit'   \n",
      "1      '0<=X<200'        48                   'existing paid'   \n",
      "2   'no checking'        12  'critical/other existing credit'   \n",
      "3            '<0'        42                   'existing paid'   \n",
      "4            '<0'        24              'delayed previously'   \n",
      "\n",
      "               purpose  credit_amount      savings_status employment  \\\n",
      "0             radio/tv           1169  'no known savings'      '>=7'   \n",
      "1             radio/tv           5951              '<100'   '1<=X<4'   \n",
      "2            education           2096              '<100'   '4<=X<7'   \n",
      "3  furniture/equipment           7882              '<100'   '4<=X<7'   \n",
      "4            'new car'           4870              '<100'   '1<=X<4'   \n",
      "\n",
      "   installment_commitment       personal_status other_parties  ...  \\\n",
      "0                       4         'male single'          none  ...   \n",
      "1                       2  'female div/dep/mar'          none  ...   \n",
      "2                       2         'male single'          none  ...   \n",
      "3                       2         'male single'     guarantor  ...   \n",
      "4                       3         'male single'          none  ...   \n",
      "\n",
      "    property_magnitude age  other_payment_plans     housing existing_credits  \\\n",
      "0        'real estate'  67                 none         own                2   \n",
      "1        'real estate'  22                 none         own                1   \n",
      "2        'real estate'  49                 none         own                1   \n",
      "3     'life insurance'  45                 none  'for free'                1   \n",
      "4  'no known property'  53                 none  'for free'                2   \n",
      "\n",
      "                    job num_dependents  own_telephone foreign_worker class  \n",
      "0               skilled              1            yes            yes  good  \n",
      "1               skilled              1           none            yes   bad  \n",
      "2  'unskilled resident'              2           none            yes  good  \n",
      "3               skilled              2           none            yes  good  \n",
      "4               skilled              2           none            yes   bad  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Columns with 'none' values:\n",
      "  - other_parties: 907 none values\n",
      "  - other_payment_plans: 814 none values\n",
      "  - own_telephone: 596 none values\n",
      "Dropping columns: ['other_parties', 'other_payment_plans', 'own_telephone']\n",
      "\n",
      "After dropping columns:\n",
      "Shape: (1000, 18)\n",
      "Column names: ['checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings_status', 'employment', 'installment_commitment', 'personal_status', 'residence_since', 'property_magnitude', 'age', 'housing', 'existing_credits', 'job', 'num_dependents', 'foreign_worker', 'class']\n",
      "\n",
      "Unique values in checking_status:\n",
      "[\"'<0'\" \"'0<=X<200'\" \"'no checking'\" \"'>=200'\"]\n",
      "\n",
      "Unique values in savings_status:\n",
      "[\"'no known savings'\" \"'<100'\" \"'500<=X<1000'\" \"'>=1000'\" \"'100<=X<500'\"]\n"
     ]
    }
   ],
   "source": [
    "# Let's reload the data and start fresh\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the original data\n",
    "df = pd.read_csv(\"GermanCredit.csv\")\n",
    "\n",
    "# Let's first examine the data to understand its structure\n",
    "print(\"Original DataFrame Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Column names: {df.columns.tolist()}\")\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for 'none' values in each column\n",
    "print(\"\\nColumns with 'none' values:\")\n",
    "none_counts = {}\n",
    "for col in df.columns:\n",
    "    none_count = df[col].astype(str).str.lower().str.count('none').sum()\n",
    "    if none_count > 0:\n",
    "        none_counts[col] = none_count\n",
    "        print(f\"  - {col}: {none_count} none values\")\n",
    "\n",
    "# Function to find and drop columns with most 'none' values\n",
    "def drop_least_contributing_columns(dataframe, n=3):\n",
    "    none_counts = {}\n",
    "    for col in dataframe.columns:\n",
    "        # Count non-zero 'none' values (case insensitive)\n",
    "        none_count = dataframe[col].astype(str).str.lower().str.count('none').sum()\n",
    "        none_counts[col] = none_count\n",
    "    \n",
    "    # Sort by count (highest first) and then by column name\n",
    "    sorted_columns = sorted(none_counts.items(), key=lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    # Get the n columns with highest 'none' counts\n",
    "    columns_to_drop = [col for col, count in sorted_columns[:n]]\n",
    "    \n",
    "    print(f\"Dropping columns: {columns_to_drop}\")\n",
    "    return dataframe.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the 3 least contributing columns\n",
    "df_cleaned = drop_least_contributing_columns(df, n=3)\n",
    "\n",
    "# Now let's check if checking_status and savings_status are still in the DataFrame\n",
    "print(\"\\nAfter dropping columns:\")\n",
    "print(f\"Shape: {df_cleaned.shape}\")\n",
    "print(f\"Column names: {df_cleaned.columns.tolist()}\")\n",
    "\n",
    "# Check unique values in these columns\n",
    "print(\"\\nUnique values in checking_status:\")\n",
    "print(df_cleaned['checking_status'].unique() if 'checking_status' in df_cleaned.columns else \"Column not found\")\n",
    "\n",
    "print(\"\\nUnique values in savings_status:\")\n",
    "print(df_cleaned['savings_status'].unique() if 'savings_status' in df_cleaned.columns else \"Column not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing apostrophes\n",
      "['<0' '0<=X<200' 'no checking' '>=200']\n",
      "['no known savings' '<100' '500<=X<1000' '>=1000' '100<=X<500']\n",
      "\n",
      "After mapping checking_status:\n",
      "checking_status\n",
      "No Checking    394\n",
      "Low            274\n",
      "Medium         269\n",
      "High            63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After mapping savings_status:\n",
      "savings_status\n",
      "Low           603\n",
      "No Savings    183\n",
      "High          111\n",
      "Medium        103\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df_cleaned.columns:\n",
    "    if df_cleaned[col].dtype == 'object':\n",
    "        df_cleaned[col] = df_cleaned[col].str.replace(\"'\", \"\")\n",
    "print(\"After removing apostrophes\")\n",
    "print(df_cleaned['checking_status'].unique())\n",
    "print(df_cleaned['savings_status'].unique())\n",
    "\n",
    "#map checking_status values\n",
    "checking_status_mapping = {\n",
    "    'no checking': 'No Checking',\n",
    "    '<0': 'Low',\n",
    "    '0<=X<200': 'Medium',\n",
    "    '>=200': 'High'\n",
    "}\n",
    "df_cleaned['checking_status'] = df_cleaned['checking_status'].map(checking_status_mapping)\n",
    "\n",
    "print(\"\\nAfter mapping checking_status:\")\n",
    "print(df_cleaned['checking_status'].value_counts())\n",
    "\n",
    "#map savings_status values\n",
    "saving_status_mapping = {\n",
    "    'no known savings': 'No Savings',\n",
    "    '<100': 'Low',\n",
    "    '100<=X<500': 'Medium',\n",
    "    '500<=X<1000': 'High',\n",
    "    '>=1000': 'High'\n",
    "}\n",
    "df_cleaned['savings_status'] = df_cleaned['savings_status'].map(saving_status_mapping)\n",
    "\n",
    "print(\"\\nAfter mapping savings_status:\")\n",
    "print(df_cleaned['savings_status'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
